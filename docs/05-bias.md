# Bias in Generative Art

If you take the prompt, "A picture of a CIO", we might get mostly males.  This is because many photos that are tagged as "CEO" include photos of males.

To minimize this bias, generative art programs can detect when occupations are added to the prompt.  They can then place gender adjectives before the occupation such as "male" or "female".  Many new generative products do not warn you or correct this problem.

[Reducing Bias and
Improving Safety in DALLÂ·E 2](https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2/)