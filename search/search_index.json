{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Generative Art \u00b6 This site describes the field of generative art: the process of converting narrative text into images. Why this Course \u00b6 This course will teach you about how to create prompts to guild text-to-image algorithms. It will also introduce you to many of the concepts in natural language processing and machine learning. However, the biggest reason to take this course is because it is FUN . Generating beautiful images from short descriptive text is one of the most empowering feelings we can get today. We hope you enjoy the course. Sample Course Content \u00b6 What is generative art? Examples of generative art Products that create images from descriptive text Prompt design Concepts Bias Searching generated art Activities Glossary References Contacts","title":"Introduction"},{"location":"#generative-art","text":"This site describes the field of generative art: the process of converting narrative text into images.","title":"Generative Art"},{"location":"#why-this-course","text":"This course will teach you about how to create prompts to guild text-to-image algorithms. It will also introduce you to many of the concepts in natural language processing and machine learning. However, the biggest reason to take this course is because it is FUN . Generating beautiful images from short descriptive text is one of the most empowering feelings we can get today. We hope you enjoy the course.","title":"Why this Course"},{"location":"#sample-course-content","text":"What is generative art? Examples of generative art Products that create images from descriptive text Prompt design Concepts Bias Searching generated art Activities Glossary References Contacts","title":"Sample Course Content"},{"location":"01-intro/","text":"Generative Art \u00b6 This site describes the field of generative art: the process of converting narrative text into images. Sample Content What is generative art? Examples of generative art Text to image products that create images from descriptive text Prompt design Concepts Bias Activities Glossary Contacts Source: Types of Cyber Security Roles: Job Growth and Career Paths","title":"Introduction"},{"location":"01-intro/#generative-art","text":"This site describes the field of generative art: the process of converting narrative text into images. Sample Content What is generative art? Examples of generative art Text to image products that create images from descriptive text Prompt design Concepts Bias Activities Glossary Contacts Source: Types of Cyber Security Roles: Job Growth and Career Paths","title":"Generative Art"},{"location":"03-concepts/","text":"Generative Art Concepts \u00b6 Prompt Engineering \u00b6 Zero-Shot Learning \u00b6 Styles \u00b6 Style Transfer \u00b6 Challenges \u00b6 Faces \u00b6 Hands \u00b6","title":"Concepts"},{"location":"03-concepts/#generative-art-concepts","text":"","title":"Generative Art Concepts"},{"location":"03-concepts/#prompt-engineering","text":"","title":"Prompt Engineering"},{"location":"03-concepts/#zero-shot-learning","text":"","title":"Zero-Shot Learning"},{"location":"03-concepts/#styles","text":"","title":"Styles"},{"location":"03-concepts/#style-transfer","text":"","title":"Style Transfer"},{"location":"03-concepts/#challenges","text":"","title":"Challenges"},{"location":"03-concepts/#faces","text":"","title":"Faces"},{"location":"03-concepts/#hands","text":"","title":"Hands"},{"location":"04-prompts/","text":"Prompt Design \u00b6 Prompt design is the art and science of creating a short descriptive text that is given to a language model. Some systems such as OpenAI's GPT-3 also allow you to give a sequence of examples of what you would like returned. In the future, Example with GPT-3 \u00b6 Prompt: 1 2 3 4 5 6 Create an outline for a class on prompt design using large language models such as GPT - 3 . 1 . What is prompt engineering 2 . Designing prompts 3 . Prompt length 4 . Results: 1 2 3 4 5 Prompt type 5. Prompt structure 6. Prompt content 7. Generating prompts with GPT-3 8. Evaluating prompts Prompts in Text to Image \u00b6 Prompts in most text-to-image systems are limited to around 20 words. They often have to parts: The objects to be rendered The style of rendering. The styles frequently reference: An type of image (drawing, painting, photo, sketch, blueprint) The class of art (impressionism, surrealist) A specific painter (Vincent Van Goah, Dali) A specific painting (Daybreak by Maxfield Parrish) A series of adjectives of how you want the image rendered (bright, detailed) One of the best ways to learn prompt design is to go to the stable diffusion search engine Lexica and view the prompts that generate the art you are interested in. Understanding Context of a Style \u00b6 Not all artists will render all objects. For example, if you pick a painter that didn't do representational art, like Mark Rothko or Piet Mondriaan , and you give a prompt such as \"Girl with laptop in the style of Mark Rothko\" you will only get highly abstract art, but not a detailed person. A girl with a laptop in the style of Mark Rothko A girl with a laptop in the style of Piet Mondrian In contrast, the artist Rembrandt did many finely detailed drawings of people, so these images will come out in high detail: ![A girl with a laptop in the style of Rembrandt](../imga_girl_with_a_laptop_in_the_style_of_rembrandt.png A girl with a laptop in the style of Rembrandt","title":"Prompt Design"},{"location":"04-prompts/#prompt-design","text":"Prompt design is the art and science of creating a short descriptive text that is given to a language model. Some systems such as OpenAI's GPT-3 also allow you to give a sequence of examples of what you would like returned. In the future,","title":"Prompt Design"},{"location":"04-prompts/#example-with-gpt-3","text":"Prompt: 1 2 3 4 5 6 Create an outline for a class on prompt design using large language models such as GPT - 3 . 1 . What is prompt engineering 2 . Designing prompts 3 . Prompt length 4 . Results: 1 2 3 4 5 Prompt type 5. Prompt structure 6. Prompt content 7. Generating prompts with GPT-3 8. Evaluating prompts","title":"Example with GPT-3"},{"location":"04-prompts/#prompts-in-text-to-image","text":"Prompts in most text-to-image systems are limited to around 20 words. They often have to parts: The objects to be rendered The style of rendering. The styles frequently reference: An type of image (drawing, painting, photo, sketch, blueprint) The class of art (impressionism, surrealist) A specific painter (Vincent Van Goah, Dali) A specific painting (Daybreak by Maxfield Parrish) A series of adjectives of how you want the image rendered (bright, detailed) One of the best ways to learn prompt design is to go to the stable diffusion search engine Lexica and view the prompts that generate the art you are interested in.","title":"Prompts in Text to Image"},{"location":"04-prompts/#understanding-context-of-a-style","text":"Not all artists will render all objects. For example, if you pick a painter that didn't do representational art, like Mark Rothko or Piet Mondriaan , and you give a prompt such as \"Girl with laptop in the style of Mark Rothko\" you will only get highly abstract art, but not a detailed person. A girl with a laptop in the style of Mark Rothko A girl with a laptop in the style of Piet Mondrian In contrast, the artist Rembrandt did many finely detailed drawings of people, so these images will come out in high detail: ![A girl with a laptop in the style of Rembrandt](../imga_girl_with_a_laptop_in_the_style_of_rembrandt.png A girl with a laptop in the style of Rembrandt","title":"Understanding Context of a Style"},{"location":"05-bias/","text":"Bias in Generative Art \u00b6 If you take the prompt, \"A picture of a CIO\", we might get mostly males. This is because many photos that are tagged as \"CEO\" include photos of males. To minimize this bias, generative art programs can detect when occupations are added to the prompt. They can then place gender adjectives before the occupation such as \"male\" or \"female\". Many new generative products do not warn you or correct this problem. Reducing Bias and Improving Safety in DALL\u00b7E 2","title":"Bias"},{"location":"05-bias/#bias-in-generative-art","text":"If you take the prompt, \"A picture of a CIO\", we might get mostly males. This is because many photos that are tagged as \"CEO\" include photos of males. To minimize this bias, generative art programs can detect when occupations are added to the prompt. They can then place gender adjectives before the occupation such as \"male\" or \"female\". Many new generative products do not warn you or correct this problem. Reducing Bias and Improving Safety in DALL\u00b7E 2","title":"Bias in Generative Art"},{"location":"06-fine-tuning/","text":"Fine Tuning a Text-to-Image Model \u00b6 Intro \u00b6 Fine-tuning is the process of adding new layers to an existing model to get it to perform better on a give task. Steps \u00b6 Find an existing model HuggingFace Text-to-Image Models Download the model to your local computer Create a set of images you want to use to fine-tune the model Add new layers to the network and train their weights using these images Waifu Diffusion \u00b6 Waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning. The image dataset for fine tuning was 56k images chosesen from the Danbooru image database. Waifu-diffusion Sample Code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import gradio as gr import torch from torch import autocast from diffusers import StableDiffusionPipeline # our new model ID model_id = \"hakurei/waifu-diffusion\" # use this only if you have a GPU from NVIDIA device = \"cuda\" # we create a new pipeline with our model id using a 16-bit floating point representation pipe = StableDiffusionPipeline . from_pretrained ( model_id , torch_dtype = torch . float16 , revision = 'fp16' ) pipe = pipe . to ( device ) block = gr . Blocks ( css = \".container { max-width: 800px; margin: auto; }\" ) num_samples = 2 def infer ( prompt ): with autocast ( \"cuda\" ): images = pipe ([ prompt ] * num_samples , guidance_scale = 7.5 )[ \"sample\" ] return images with block as demo : gr . Markdown ( \"<h1><center>Waifu Diffusion</center></h1>\" ) gr . Markdown ( \"waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning.\" ) with gr . Group (): with gr . Box (): with gr . Row () . style ( mobile_collapse = False , equal_height = True ): text = gr . Textbox ( label = \"Enter your prompt\" , show_label = False , max_lines = 1 ) . style ( border = ( True , False , True , True ), rounded = ( True , False , False , True ), container = False , ) btn = gr . Button ( \"Run\" ) . style ( margin = False , rounded = ( False , True , True , False ), ) gallery = gr . Gallery ( label = \"Generated images\" , show_label = False ) . style ( grid = [ 2 ], height = \"auto\" ) text . submit ( infer , inputs = [ text ], outputs = gallery ) btn . click ( infer , inputs = [ text ], outputs = gallery ) gr . Markdown ( \"\"\"___ <p style='text-align: center'> Created by https://huggingface.co/hakurei <br/> </p>\"\"\" ) demo . launch ( debug = True )","title":"Fine Tuning"},{"location":"06-fine-tuning/#fine-tuning-a-text-to-image-model","text":"","title":"Fine Tuning a Text-to-Image Model"},{"location":"06-fine-tuning/#intro","text":"Fine-tuning is the process of adding new layers to an existing model to get it to perform better on a give task.","title":"Intro"},{"location":"06-fine-tuning/#steps","text":"Find an existing model HuggingFace Text-to-Image Models Download the model to your local computer Create a set of images you want to use to fine-tune the model Add new layers to the network and train their weights using these images","title":"Steps"},{"location":"06-fine-tuning/#waifu-diffusion","text":"Waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning. The image dataset for fine tuning was 56k images chosesen from the Danbooru image database. Waifu-diffusion","title":"Waifu Diffusion"},{"location":"06-fine-tuning/#sample-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import gradio as gr import torch from torch import autocast from diffusers import StableDiffusionPipeline # our new model ID model_id = \"hakurei/waifu-diffusion\" # use this only if you have a GPU from NVIDIA device = \"cuda\" # we create a new pipeline with our model id using a 16-bit floating point representation pipe = StableDiffusionPipeline . from_pretrained ( model_id , torch_dtype = torch . float16 , revision = 'fp16' ) pipe = pipe . to ( device ) block = gr . Blocks ( css = \".container { max-width: 800px; margin: auto; }\" ) num_samples = 2 def infer ( prompt ): with autocast ( \"cuda\" ): images = pipe ([ prompt ] * num_samples , guidance_scale = 7.5 )[ \"sample\" ] return images with block as demo : gr . Markdown ( \"<h1><center>Waifu Diffusion</center></h1>\" ) gr . Markdown ( \"waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning.\" ) with gr . Group (): with gr . Box (): with gr . Row () . style ( mobile_collapse = False , equal_height = True ): text = gr . Textbox ( label = \"Enter your prompt\" , show_label = False , max_lines = 1 ) . style ( border = ( True , False , True , True ), rounded = ( True , False , False , True ), container = False , ) btn = gr . Button ( \"Run\" ) . style ( margin = False , rounded = ( False , True , True , False ), ) gallery = gr . Gallery ( label = \"Generated images\" , show_label = False ) . style ( grid = [ 2 ], height = \"auto\" ) text . submit ( infer , inputs = [ text ], outputs = gallery ) btn . click ( infer , inputs = [ text ], outputs = gallery ) gr . Markdown ( \"\"\"___ <p style='text-align: center'> Created by https://huggingface.co/hakurei <br/> </p>\"\"\" ) demo . launch ( debug = True )","title":"Sample Code"},{"location":"08-whats-next/","text":"What's Next for Generative Art \u00b6 Image resolution \u00b6 Quality \u00b6 Customizability \u00b6 Video \u00b6","title":"Whats Next"},{"location":"08-whats-next/#whats-next-for-generative-art","text":"","title":"What's Next for Generative Art"},{"location":"08-whats-next/#image-resolution","text":"","title":"Image resolution"},{"location":"08-whats-next/#quality","text":"","title":"Quality"},{"location":"08-whats-next/#customizability","text":"","title":"Customizability"},{"location":"08-whats-next/#video","text":"","title":"Video"},{"location":"contacts/","text":"Generative Art Contacts \u00b6 General Code Savvy Contact \u00b6 kidscode@codesavvy.org Contact for CoderDojo Twin Cities \u00b6 hello@coderdojotc.org Specific questions on this repository \u00b6 Dan McCreary","title":"Contacts"},{"location":"contacts/#generative-art-contacts","text":"","title":"Generative Art Contacts"},{"location":"contacts/#general-code-savvy-contact","text":"kidscode@codesavvy.org","title":"General Code Savvy Contact"},{"location":"contacts/#contact-for-coderdojo-twin-cities","text":"hello@coderdojotc.org","title":"Contact for CoderDojo Twin Cities"},{"location":"contacts/#specific-questions-on-this-repository","text":"Dan McCreary","title":"Specific questions on this repository"},{"location":"glossary/","text":"Glossary of Terms for Text to Image Project \u00b6 API Key \u00b6 A key that is assigned to a developer to use a specific programming interface. The key is used to associate billing with the service. Many commercial text-to-image systems require the user to register with a credit card to get an API Key. Images generated are billed to a credit card each month. BERT \u00b6 Bidirectional Encoder Representations from Transformers (BERT) is a transformer -based machine learning technique for [natural language processing] (NLP) pre-training developed by Google. See also: Wikipedia on BERT Content \u00b6 The information is conveyed by an image. For example, the mood, the message, or the story. Deep Neural Network \u00b6 A type of neural network with multiple layers between the input and output layers. See also: Wikipedia on DNN Domain \u00b6 The subject matter or context of an image. For example, a landscape, a portrait, a still life, or an abstract image. Embedding \u00b6 A vector of scalar numbers used to map a word or phrase into the mathematical structure for comparison using distance measurements. Fine Tuning \u00b6 The process of adding a small additional output layer to an existing model to give specific results. For example, diagrams that need to conform to Optum 2022 color themes would need to fine-tune a basic model. Gender Bias \u00b6 The tendency of machine learning models to favor one gender or another for specific situations. The most common of these is occupations or roles. For example, the BERT large language model generates an 83% chance that a \"nurse\" will be female, but only a See also: Showing Bias in BERT Generative Adversarial Network \u00b6 A neural network architecture used for image generation that uses dueling neural networks to genrate and judge the quality of images. Also known as: GAN Perceptual loss \u00b6 A loss function used in image generation that measures the difference between two images in a way that is perceptually meaningful to humans. Generative Model \u00b6 A machine learning model used to generate images from text descriptions. HuggingFace \u00b6 The largest collection of machine learning models and tools to fine-tune these models. As of August 2022, HuggingFace has 28 image to text models. See HuggingFace Text to Image Models Image synthesis \u00b6 The process of creating a new image from a set of input images. Multi-model Models \u00b6 Models that convert one medium into another medium. For example text-to-image, image-to-text, speech-to-text, text-to-speech etc. Many of the models can be fine-tuned to generate other representations such as text-to-line-art or text-to-architecture-diagram. Texture synthesis \u00b6 The process of creating a texture from a set of input textures Neural Network \u00b6 A machine learning model composed of a large number of interconnected processing nodes, or neurons, that can learn to recognize patterns of input data. Text-to-image models almost all use deep neural networks that contain millions or billions of parameters. Max Tokens \u00b6 The maximum number of tokens used by a prompt. After this limit is reached the text is ignored. The max-tokens for standard language models such as BERT are usually 512 tokens. Larger models such as GPT-3 are 2K or 4K tokens. Style \u00b6 The style used to render an image. For example, a photo, a cartoon, a wireframe, a sketch, line art, a painter or a painting. Prompts that desire a specific style can add the suffix such as \"in the style of...\" Style Transfer \u00b6 The process of creating an image in the style of another style, artist, image or type of image. For example, \"A cat in a field in the style of Vincent Van Goh\" Stable Diffusion \u00b6 The most popular text-to-image model on HuggingFace. See HuggingFace Training Bias \u00b6 The training data used to train a machine learning model. This data can influence the results of the model. Prompt \u00b6 The descriptive text that is given to generate an image. Text to Image \u00b6 The process of generating images from a text description using large langauge models. Tokenization \u00b6 The way that descriptive text is converted into a sequence of numeric values. Small common words are usually a single token. Uncommon multi-syllable words are often many tokens.","title":"Glossary"},{"location":"glossary/#glossary-of-terms-for-text-to-image-project","text":"","title":"Glossary of Terms for Text to Image Project"},{"location":"glossary/#api-key","text":"A key that is assigned to a developer to use a specific programming interface. The key is used to associate billing with the service. Many commercial text-to-image systems require the user to register with a credit card to get an API Key. Images generated are billed to a credit card each month.","title":"API Key"},{"location":"glossary/#bert","text":"Bidirectional Encoder Representations from Transformers (BERT) is a transformer -based machine learning technique for [natural language processing] (NLP) pre-training developed by Google. See also: Wikipedia on BERT","title":"BERT"},{"location":"glossary/#content","text":"The information is conveyed by an image. For example, the mood, the message, or the story.","title":"Content"},{"location":"glossary/#deep-neural-network","text":"A type of neural network with multiple layers between the input and output layers. See also: Wikipedia on DNN","title":"Deep Neural Network"},{"location":"glossary/#domain","text":"The subject matter or context of an image. For example, a landscape, a portrait, a still life, or an abstract image.","title":"Domain"},{"location":"glossary/#embedding","text":"A vector of scalar numbers used to map a word or phrase into the mathematical structure for comparison using distance measurements.","title":"Embedding"},{"location":"glossary/#fine-tuning","text":"The process of adding a small additional output layer to an existing model to give specific results. For example, diagrams that need to conform to Optum 2022 color themes would need to fine-tune a basic model.","title":"Fine Tuning"},{"location":"glossary/#gender-bias","text":"The tendency of machine learning models to favor one gender or another for specific situations. The most common of these is occupations or roles. For example, the BERT large language model generates an 83% chance that a \"nurse\" will be female, but only a See also: Showing Bias in BERT","title":"Gender Bias"},{"location":"glossary/#generative-adversarial-network","text":"A neural network architecture used for image generation that uses dueling neural networks to genrate and judge the quality of images. Also known as: GAN","title":"Generative Adversarial Network"},{"location":"glossary/#perceptual-loss","text":"A loss function used in image generation that measures the difference between two images in a way that is perceptually meaningful to humans.","title":"Perceptual loss"},{"location":"glossary/#generative-model","text":"A machine learning model used to generate images from text descriptions.","title":"Generative Model"},{"location":"glossary/#huggingface","text":"The largest collection of machine learning models and tools to fine-tune these models. As of August 2022, HuggingFace has 28 image to text models. See HuggingFace Text to Image Models","title":"HuggingFace"},{"location":"glossary/#image-synthesis","text":"The process of creating a new image from a set of input images.","title":"Image synthesis"},{"location":"glossary/#multi-model-models","text":"Models that convert one medium into another medium. For example text-to-image, image-to-text, speech-to-text, text-to-speech etc. Many of the models can be fine-tuned to generate other representations such as text-to-line-art or text-to-architecture-diagram.","title":"Multi-model Models"},{"location":"glossary/#texture-synthesis","text":"The process of creating a texture from a set of input textures","title":"Texture synthesis"},{"location":"glossary/#neural-network","text":"A machine learning model composed of a large number of interconnected processing nodes, or neurons, that can learn to recognize patterns of input data. Text-to-image models almost all use deep neural networks that contain millions or billions of parameters.","title":"Neural Network"},{"location":"glossary/#max-tokens","text":"The maximum number of tokens used by a prompt. After this limit is reached the text is ignored. The max-tokens for standard language models such as BERT are usually 512 tokens. Larger models such as GPT-3 are 2K or 4K tokens.","title":"Max Tokens"},{"location":"glossary/#style","text":"The style used to render an image. For example, a photo, a cartoon, a wireframe, a sketch, line art, a painter or a painting. Prompts that desire a specific style can add the suffix such as \"in the style of...\"","title":"Style"},{"location":"glossary/#style-transfer","text":"The process of creating an image in the style of another style, artist, image or type of image. For example, \"A cat in a field in the style of Vincent Van Goh\"","title":"Style Transfer"},{"location":"glossary/#stable-diffusion","text":"The most popular text-to-image model on HuggingFace. See HuggingFace","title":"Stable Diffusion"},{"location":"glossary/#training-bias","text":"The training data used to train a machine learning model. This data can influence the results of the model.","title":"Training Bias"},{"location":"glossary/#prompt","text":"The descriptive text that is given to generate an image.","title":"Prompt"},{"location":"glossary/#text-to-image","text":"The process of generating images from a text description using large langauge models.","title":"Text to Image"},{"location":"glossary/#tokenization","text":"The way that descriptive text is converted into a sequence of numeric values. Small common words are usually a single token. Uncommon multi-syllable words are often many tokens.","title":"Tokenization"},{"location":"references/","text":"Generative Art Resources \u00b6 Wikipedia Page on Generative Art Open AI Dall-E 2 Hierarchical Text-Conditional Image Generation with CLIP Latents Ars Technica: With Stable Diffusion, you may never believe what you see online again Sept 6th, 2022 https://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf - This 2015 paper broke ground in the use of GANs to generate human faces. ANDREI KOVALEV'S MIDJOURNEY AI STYLES LIBRARY","title":"References"},{"location":"references/#generative-art-resources","text":"Wikipedia Page on Generative Art Open AI Dall-E 2 Hierarchical Text-Conditional Image Generation with CLIP Latents Ars Technica: With Stable Diffusion, you may never believe what you see online again Sept 6th, 2022 https://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf - This 2015 paper broke ground in the use of GANs to generate human faces. ANDREI KOVALEV'S MIDJOURNEY AI STYLES LIBRARY","title":"Generative Art Resources"},{"location":"activities/01-intro/","text":"Introduction to Hands-On Activities \u00b6","title":"Introduction"},{"location":"activities/01-intro/#introduction-to-hands-on-activities","text":"","title":"Introduction to Hands-On Activities"},{"location":"activities/02-dalle2/","text":"Dall-E 2 \u00b6 About Dall-E 2 \u00b6 DALL\u00b7E 2 is a new AI system that can create realistic images and art from a description in natural language ( in English for now ). How do I get access to Dall-E 2? \u00b6 Currently there is a waitlist. ( Sign up here ). You will have to wait a few days before you get an invitation email. Once you do, you will be able to use just a browser to start working with Dall-E 2 to generate amazing scenes. What does Dall-E 2 learn? \u00b6 DALL\u00b7E 2 has learned the relationship between images and the text used to describe them. It uses a process called \u201cdiffusion,\u201d which starts with a pattern of random dots and gradually alters that pattern towards an image when it recognizes specific aspects of that image. How do I prompt Dall-E to generate images? \u00b6 There are three general elements to a prompt: 1. The object, for e.g. \"teddy bears\" 2. The scene, for e.g. \"shopping for groceries\" 3. The style, for e.g. \"as a pencil drawing\", or \"in a photorealistic style\", or \"in ancient egypt\". So the full prompts would look like: 1. Teddy bears shopping for groceries, in ancient Egypt 2. Teddy bears shopping for groceries, as a pencil drawing 3. Teddy bears shopping for groceries, in a photorealistic style By varying the words in the prompt, you can generate an infinite amount of art. Since Dall-E 2 has been trained with an enormous amount of \"words, image\" pairs, we really don't know what Dall-E really knows. The best way is to try different things, and learn from what others on the internet have learned by trying. Prompt responsibly \u00b6 The creators of Dall-E 2, OpenAI are trying hard to limit offensive language in the prompts as well as the images that are generated. However, we all need to use this powerful AI as responsibly as we can too. If you see offensive images being generated, you can flag them as such. Style Hints \u00b6 Here are some styles that people have discovered: - Output styles: --3D render, digital art -- artists such as claude monet, picasso, van gogh, raja ravi varma, leonardo da vinci -- painting such as mona lisa - emotions such as : cute, dynamic - color hint - such as \"green desert\" - ... Example Prompts \u00b6 There are many guides for Dall-E prompts. Here is a good one . Inpainting \u00b6 Using the editor's eraser tool, you can ask Dall-E to \"paint inside\" the erased area using the prompt you provide. For example, say you upload a picture with your car in front of a mountain. You can erase a circular portion of the sky and prompt Dall-E to generate a moon or sun in that circle! Outpainting \u00b6 Dall-E 2 will generate a scene in a 1024x1024 frame. Sometimes you want to extend a scene. You can do this using a feature called Outpainting . Its really simple - you add a generation frame using the editor to an edge of the image and ask Dall-E to \"regnerate\" a new image variation based on the original. Once you accept one of the few ( generally 4 ) variations, you can repeat this step to keep painting \"outwards\".","title":"Dall-E 2"},{"location":"activities/02-dalle2/#dall-e-2","text":"","title":"Dall-E 2"},{"location":"activities/02-dalle2/#about-dall-e-2","text":"DALL\u00b7E 2 is a new AI system that can create realistic images and art from a description in natural language ( in English for now ).","title":"About Dall-E 2"},{"location":"activities/02-dalle2/#how-do-i-get-access-to-dall-e-2","text":"Currently there is a waitlist. ( Sign up here ). You will have to wait a few days before you get an invitation email. Once you do, you will be able to use just a browser to start working with Dall-E 2 to generate amazing scenes.","title":"How do I get access to Dall-E 2?"},{"location":"activities/02-dalle2/#what-does-dall-e-2-learn","text":"DALL\u00b7E 2 has learned the relationship between images and the text used to describe them. It uses a process called \u201cdiffusion,\u201d which starts with a pattern of random dots and gradually alters that pattern towards an image when it recognizes specific aspects of that image.","title":"What does Dall-E 2 learn?"},{"location":"activities/02-dalle2/#how-do-i-prompt-dall-e-to-generate-images","text":"There are three general elements to a prompt: 1. The object, for e.g. \"teddy bears\" 2. The scene, for e.g. \"shopping for groceries\" 3. The style, for e.g. \"as a pencil drawing\", or \"in a photorealistic style\", or \"in ancient egypt\". So the full prompts would look like: 1. Teddy bears shopping for groceries, in ancient Egypt 2. Teddy bears shopping for groceries, as a pencil drawing 3. Teddy bears shopping for groceries, in a photorealistic style By varying the words in the prompt, you can generate an infinite amount of art. Since Dall-E 2 has been trained with an enormous amount of \"words, image\" pairs, we really don't know what Dall-E really knows. The best way is to try different things, and learn from what others on the internet have learned by trying.","title":"How do I prompt Dall-E to generate images?"},{"location":"activities/02-dalle2/#prompt-responsibly","text":"The creators of Dall-E 2, OpenAI are trying hard to limit offensive language in the prompts as well as the images that are generated. However, we all need to use this powerful AI as responsibly as we can too. If you see offensive images being generated, you can flag them as such.","title":"Prompt responsibly"},{"location":"activities/02-dalle2/#style-hints","text":"Here are some styles that people have discovered: - Output styles: --3D render, digital art -- artists such as claude monet, picasso, van gogh, raja ravi varma, leonardo da vinci -- painting such as mona lisa - emotions such as : cute, dynamic - color hint - such as \"green desert\" - ...","title":"Style Hints"},{"location":"activities/02-dalle2/#example-prompts","text":"There are many guides for Dall-E prompts. Here is a good one .","title":"Example Prompts"},{"location":"activities/02-dalle2/#inpainting","text":"Using the editor's eraser tool, you can ask Dall-E to \"paint inside\" the erased area using the prompt you provide. For example, say you upload a picture with your car in front of a mountain. You can erase a circular portion of the sky and prompt Dall-E to generate a moon or sun in that circle!","title":"Inpainting"},{"location":"activities/02-dalle2/#outpainting","text":"Dall-E 2 will generate a scene in a 1024x1024 frame. Sometimes you want to extend a scene. You can do this using a feature called Outpainting . Its really simple - you add a generation frame using the editor to an edge of the image and ask Dall-E to \"regnerate\" a new image variation based on the original. Once you accept one of the few ( generally 4 ) variations, you can repeat this step to keep painting \"outwards\".","title":"Outpainting"},{"location":"activities/03-midjourney/","text":"MidJourney \u00b6 Midjourney is a text-to-image generation app similar to OpenAI\u2019s DALLE-2 and Stable Diffusion\u2019s DreamStudio , which uses around 400+ million images found on the internet to generate images based on the text prompt provided. Midjourney is an independent research lab exploring new mediums of thought and expanding the imaginative powers of the human species. Getting Started \u00b6 Note: MidJourney uses Discord as an interface. If you don't have a Discord accound you can create one by going to discord.com Join MidJourney's Discord Server https://discord.gg/midjourney Navigate to the \"Newcomers Room\" In the input box us /imagine prompt to get started Complete Getting Started Instructions (Docs) Sample Prompts \u00b6 1 cute beta fish character by Disney, artgerm, pixar, Ghibli . 1 Tiny cute adorable baby fox, intricate furry details, soft cinematic lighting, 8k, portrait, Pixar style character, pokemon anime style octane render : : 1 intricate furry details, soft cinematic lighting, 8k, portrait, Pixar style character, pokemon anime style octane render, blue, teal, purple, Tiny cute adorable baby fantasy character, it has a fox head, lemur body, lemur eyes, owl wings on its back, lemur tail, spread wings, purple blue and teal feathered wings, purple blue and teal fur , it is sitting in a forest, 1 a white horse baby wearing soft royal dress, super cute, cinematic lighting, intricate filigree design, Pixar style, anthropomorphic ,holding a pink lotus, big eyes, smile, peach blossom, stream, charming, immortal, fluffy, shiny mane, ptals, fairy tales, illusory engine 5 and Octane Render,incredibly detailed, 4k, trending on artstation, Gorgeous,ultra wide angle, 4K 1 A super cute and attractive white baby tiger,wearing short sweater,anthropomorphic, Pixar style, standing,slept on red maple leaves,big charming eyes,fluffy and shiny mane,red maple leaves background,octane number rendering and unreal engine 5,ultra wide angle Image Parameters \u00b6 https://midjourney.gitbook.io/docs/imagine-parameters /imagine parameters should follow the below order: /imagine prompt: https://example/tulip.jpg a field of tulips in the style of Mary Blair --no farms --iw .5 --ar 3:2 Styles \u00b6 Design Style[1] \u00b6 Artist Styles[2] \u00b6 Lighting Styles[3] \u00b6 MidJourney Showcase \u00b6 https://www.midjourney.com/showcase/ Sources \u00b6 1 | Design Styles by Lars Nielsen from blog on \"An advanced guide to writing prompts for Midjourney ( text-to-image)\" 2 | Artist Styles by Lars Nielsen from blog on \"An advanced guide to writing prompts for Midjourney ( text-to-image)\" 3 | Lighting Styles by Lars Nielsen from blog on \"An advanced guide to writing prompts for Midjourney ( text-to-image)\"","title":"Midjourney"},{"location":"activities/03-midjourney/#midjourney","text":"Midjourney is a text-to-image generation app similar to OpenAI\u2019s DALLE-2 and Stable Diffusion\u2019s DreamStudio , which uses around 400+ million images found on the internet to generate images based on the text prompt provided. Midjourney is an independent research lab exploring new mediums of thought and expanding the imaginative powers of the human species.","title":"MidJourney"},{"location":"activities/03-midjourney/#getting-started","text":"Note: MidJourney uses Discord as an interface. If you don't have a Discord accound you can create one by going to discord.com Join MidJourney's Discord Server https://discord.gg/midjourney Navigate to the \"Newcomers Room\" In the input box us /imagine prompt to get started Complete Getting Started Instructions (Docs)","title":"Getting Started"},{"location":"activities/03-midjourney/#sample-prompts","text":"1 cute beta fish character by Disney, artgerm, pixar, Ghibli . 1 Tiny cute adorable baby fox, intricate furry details, soft cinematic lighting, 8k, portrait, Pixar style character, pokemon anime style octane render : : 1 intricate furry details, soft cinematic lighting, 8k, portrait, Pixar style character, pokemon anime style octane render, blue, teal, purple, Tiny cute adorable baby fantasy character, it has a fox head, lemur body, lemur eyes, owl wings on its back, lemur tail, spread wings, purple blue and teal feathered wings, purple blue and teal fur , it is sitting in a forest, 1 a white horse baby wearing soft royal dress, super cute, cinematic lighting, intricate filigree design, Pixar style, anthropomorphic ,holding a pink lotus, big eyes, smile, peach blossom, stream, charming, immortal, fluffy, shiny mane, ptals, fairy tales, illusory engine 5 and Octane Render,incredibly detailed, 4k, trending on artstation, Gorgeous,ultra wide angle, 4K 1 A super cute and attractive white baby tiger,wearing short sweater,anthropomorphic, Pixar style, standing,slept on red maple leaves,big charming eyes,fluffy and shiny mane,red maple leaves background,octane number rendering and unreal engine 5,ultra wide angle","title":"Sample Prompts"},{"location":"activities/03-midjourney/#image-parameters","text":"https://midjourney.gitbook.io/docs/imagine-parameters /imagine parameters should follow the below order: /imagine prompt: https://example/tulip.jpg a field of tulips in the style of Mary Blair --no farms --iw .5 --ar 3:2","title":"Image Parameters"},{"location":"activities/03-midjourney/#styles","text":"","title":"Styles"},{"location":"activities/03-midjourney/#design-style1","text":"","title":"Design Style[1]"},{"location":"activities/03-midjourney/#artist-styles2","text":"","title":"Artist Styles[2]"},{"location":"activities/03-midjourney/#lighting-styles3","text":"","title":"Lighting Styles[3]"},{"location":"activities/03-midjourney/#midjourney-showcase","text":"https://www.midjourney.com/showcase/","title":"MidJourney Showcase"},{"location":"activities/03-midjourney/#sources","text":"1 | Design Styles by Lars Nielsen from blog on \"An advanced guide to writing prompts for Midjourney ( text-to-image)\" 2 | Artist Styles by Lars Nielsen from blog on \"An advanced guide to writing prompts for Midjourney ( text-to-image)\" 3 | Lighting Styles by Lars Nielsen from blog on \"An advanced guide to writing prompts for Midjourney ( text-to-image)\"","title":"Sources"},{"location":"activities/04-stable-diffusion/","text":"Stable Diffusion Lab \u00b6 This lab is challenging since the render time on the HuggingFace site is around five minutes, so we will only perform a few tests. Girl at Computer \u00b6 Prompt: An African girl having fun at her computer. Result: This prompt shows that Stable Diffusion does well at faces, but falls short when rendering hands.","title":"Stable Diffusion"},{"location":"activities/04-stable-diffusion/#stable-diffusion-lab","text":"This lab is challenging since the render time on the HuggingFace site is around five minutes, so we will only perform a few tests.","title":"Stable Diffusion Lab"},{"location":"activities/04-stable-diffusion/#girl-at-computer","text":"Prompt: An African girl having fun at her computer. Result: This prompt shows that Stable Diffusion does well at faces, but falls short when rendering hands.","title":"Girl at Computer"},{"location":"activities/05-crayion/","text":"Crayion Lab \u00b6 Go to the website http://www.craiyon.com and enter a prompt. Example: A happy African girl at her computer","title":"Crayion"},{"location":"activities/05-crayion/#crayion-lab","text":"Go to the website http://www.craiyon.com and enter a prompt. Example: A happy African girl at her computer","title":"Crayion Lab"},{"location":"examples/","text":"Examples of Images Generated by Text-to-Image Models \u00b6 There are now millions of sample images created by text-to-image generation tools. In this area we discuss some of these images classifications. Using Lexia \u00b6 One of the best ways to get a feeling of what these tools is capable of is to use the Lexia Sable Diffusion Search Engine . Once you find a single image that inspires you, you can click on that image, see the prompt, Seed, Guidance scale and Dimensions. You can also: Copy the prompt Copy the URL Expand the size of the similar images Use this image as a basis for other search results using the \"Explore This Style\" You will note that these images are not manually \"tagged\" with metadata for search results. The search engine uses embeddings to find similar images. Artists \u00b6 Artists Landscapes \u00b6 Landscapes Girl with Laptop \u00b6 Girl with Laptop Examples","title":"Examples of Images Generated by Text-to-Image Models"},{"location":"examples/#examples-of-images-generated-by-text-to-image-models","text":"There are now millions of sample images created by text-to-image generation tools. In this area we discuss some of these images classifications.","title":"Examples of Images Generated by Text-to-Image Models"},{"location":"examples/#using-lexia","text":"One of the best ways to get a feeling of what these tools is capable of is to use the Lexia Sable Diffusion Search Engine . Once you find a single image that inspires you, you can click on that image, see the prompt, Seed, Guidance scale and Dimensions. You can also: Copy the prompt Copy the URL Expand the size of the similar images Use this image as a basis for other search results using the \"Explore This Style\" You will note that these images are not manually \"tagged\" with metadata for search results. The search engine uses embeddings to find similar images.","title":"Using Lexia"},{"location":"examples/#artists","text":"Artists","title":"Artists"},{"location":"examples/#landscapes","text":"Landscapes","title":"Landscapes"},{"location":"examples/#girl-with-laptop","text":"Girl with Laptop Examples","title":"Girl with Laptop"},{"location":"examples/artists/","text":"Artist with Distinctive Styles \u00b6 Warning This page contains links to the Lexica stable diffusion search engine. We cannot guarantee that these search results will be safe. Famous Women Painters \u00b6 The history of art is mostly dominated by male painters. We therefor would like to being with some women that have inspired the history of art. If you have other women artists with distinctive styles, please let us know. Frida Kahlo \u00b6 Frida Kahlo was a Mexican painter known for her many portraits, self-portraits, and works inspired by the nature and artifacts of Mexico. Inspired by the country's popular culture, she employed a na\u00efve folk art style to explore questions of identity, post-colonialism, gender, class, and race in Mexican society. Her paintings often had strong autobiographical elements and mixed realism with fantasy. In addition to belonging to the post-revolutionary Mexicayotl movement, which sought to define a Mexican identity, Kahlo has been described as a surrealist or magical realist. She is known for painting about her experience of chronic pain. (from Wikipedia) Wikipedia Frida Kahlo search on Lexica Georgia O'Keeffe \u00b6 Georgia O'Keeffe was an American modernist artist. She was known for her paintings of enlarged flowers, New York skyscrapers, and New Mexico landscapes. O'Keeffe has been called the \"Mother of American modernism\". Wikipedia Lexica Mary Cassatt \u00b6 Mary Cassatt was an American painter and printmaker strongly influenced by the impressionist movement. Cassatt often created images of the social and private lives of women, with particular emphasis on the intimate bonds between mothers and children. Wikipedia Lexica Historical Artists \u00b6 Salvador Dali \u00b6 Salvador Dali was a Spanish surrealist artist renowned for his technical skill, precise draftsmanship, and the striking and bizarre images in his work. The program Dall-E (combined with Wall-E) from OpenAI was named after him. Wikipedia Lexica Diego Rivera \u00b6 Diego Rivera was a prominent Mexican painter. His large frescoes helped establish the mural movement in Mexican and international art. His Post-Impressionism style used simple forms and large patches of vivid colors. Wikipedia Lexica Jose Clemente Orozco \u00b6 Jose Clemente Orozco was a Mexican caricaturist and painter, who specialized in political murals that established the Mexican Mural Renaissance Wikipedia Lexica David Alfaro Siqueiros \u00b6 David Alfaro Siqueiros was a Mexican social realist painter, best known for his large public murals using the latest in equipment, materials and technique. Along with Diego Rivera and Jos\u00e9 Clemente Orozco, he was one of the most famous of the \"Mexican muralists\". Wikipedia Lexica Vincent van Gogh \u00b6 Vincent van Gogh was a Dutch Post-Impressionist painter who posthumously became one of the most famous and influential figures in the history of Western art. He was famed for his bold, dramatic brush strokes which expressed emotion and added a feeling of movement to his works. He often painted entire paintings in a single day. Vincent van Gogh Lexica Rembrandt \u00b6 Rembrandt is generally considered one of the greatest visual artists in the history of art and the most important in Dutch art history. Rembrandt's works depict a wide range of style and subject matter, from portraits and self-portraits to landscapes, genre scenes, allegorical and historical scenes, biblical and mythological themes and animal studies. Wikipedia Rembrandt on Lexica Graphic Artists \u00b6 Maxfield Parrish \u00b6 Maxfield Parrish was an American painter and illustrator active in the first half of the 20th century. He is known for his distinctive saturated hues and idealized neo-classical imagery. His career spanned fifty years and was wildly successful: the National Museum of American Illustration deemed his painting Daybreak (1922) to be the most successful art print of the 20th century. Wikipedia Maxfield Parrish on Lexica Alphonse Mucha \u00b6 Alfons Maria Mucha, known internationally as Alphonse Mucha, was a Czech painter, illustrator and graphic artist, living in Paris during the Art Nouveau period, best known for his distinctly stylized and decorative theatrical posters, particularly those of Sarah Bernhardt. Wikipedia Mucha on Lexica Charles Mackintosh \u00b6 Charles Mackintosh was a Scottish architect, designer, water colorist and artist. His artistic approach had much in common with European Symbolism. His work, alongside that of his wife Margaret Macdonald, was influential on European design movements such as Art Nouveau and Secessionism. He is among the most important figures of Modern Style (British Art Nouveau style). Wikipedia Lexica","title":"Artists"},{"location":"examples/artists/#artist-with-distinctive-styles","text":"Warning This page contains links to the Lexica stable diffusion search engine. We cannot guarantee that these search results will be safe.","title":"Artist with Distinctive Styles"},{"location":"examples/artists/#famous-women-painters","text":"The history of art is mostly dominated by male painters. We therefor would like to being with some women that have inspired the history of art. If you have other women artists with distinctive styles, please let us know.","title":"Famous Women Painters"},{"location":"examples/artists/#frida-kahlo","text":"Frida Kahlo was a Mexican painter known for her many portraits, self-portraits, and works inspired by the nature and artifacts of Mexico. Inspired by the country's popular culture, she employed a na\u00efve folk art style to explore questions of identity, post-colonialism, gender, class, and race in Mexican society. Her paintings often had strong autobiographical elements and mixed realism with fantasy. In addition to belonging to the post-revolutionary Mexicayotl movement, which sought to define a Mexican identity, Kahlo has been described as a surrealist or magical realist. She is known for painting about her experience of chronic pain. (from Wikipedia) Wikipedia Frida Kahlo search on Lexica","title":"Frida Kahlo"},{"location":"examples/artists/#georgia-okeeffe","text":"Georgia O'Keeffe was an American modernist artist. She was known for her paintings of enlarged flowers, New York skyscrapers, and New Mexico landscapes. O'Keeffe has been called the \"Mother of American modernism\". Wikipedia Lexica","title":"Georgia O'Keeffe"},{"location":"examples/artists/#mary-cassatt","text":"Mary Cassatt was an American painter and printmaker strongly influenced by the impressionist movement. Cassatt often created images of the social and private lives of women, with particular emphasis on the intimate bonds between mothers and children. Wikipedia Lexica","title":"Mary Cassatt"},{"location":"examples/artists/#historical-artists","text":"","title":"Historical Artists"},{"location":"examples/artists/#salvador-dali","text":"Salvador Dali was a Spanish surrealist artist renowned for his technical skill, precise draftsmanship, and the striking and bizarre images in his work. The program Dall-E (combined with Wall-E) from OpenAI was named after him. Wikipedia Lexica","title":"Salvador Dali"},{"location":"examples/artists/#diego-rivera","text":"Diego Rivera was a prominent Mexican painter. His large frescoes helped establish the mural movement in Mexican and international art. His Post-Impressionism style used simple forms and large patches of vivid colors. Wikipedia Lexica","title":"Diego Rivera"},{"location":"examples/artists/#jose-clemente-orozco","text":"Jose Clemente Orozco was a Mexican caricaturist and painter, who specialized in political murals that established the Mexican Mural Renaissance Wikipedia Lexica","title":"Jose Clemente Orozco"},{"location":"examples/artists/#david-alfaro-siqueiros","text":"David Alfaro Siqueiros was a Mexican social realist painter, best known for his large public murals using the latest in equipment, materials and technique. Along with Diego Rivera and Jos\u00e9 Clemente Orozco, he was one of the most famous of the \"Mexican muralists\". Wikipedia Lexica","title":"David Alfaro Siqueiros"},{"location":"examples/artists/#vincent-van-gogh","text":"Vincent van Gogh was a Dutch Post-Impressionist painter who posthumously became one of the most famous and influential figures in the history of Western art. He was famed for his bold, dramatic brush strokes which expressed emotion and added a feeling of movement to his works. He often painted entire paintings in a single day. Vincent van Gogh Lexica","title":"Vincent van Gogh"},{"location":"examples/artists/#rembrandt","text":"Rembrandt is generally considered one of the greatest visual artists in the history of art and the most important in Dutch art history. Rembrandt's works depict a wide range of style and subject matter, from portraits and self-portraits to landscapes, genre scenes, allegorical and historical scenes, biblical and mythological themes and animal studies. Wikipedia Rembrandt on Lexica","title":"Rembrandt"},{"location":"examples/artists/#graphic-artists","text":"","title":"Graphic Artists"},{"location":"examples/artists/#maxfield-parrish","text":"Maxfield Parrish was an American painter and illustrator active in the first half of the 20th century. He is known for his distinctive saturated hues and idealized neo-classical imagery. His career spanned fifty years and was wildly successful: the National Museum of American Illustration deemed his painting Daybreak (1922) to be the most successful art print of the 20th century. Wikipedia Maxfield Parrish on Lexica","title":"Maxfield Parrish"},{"location":"examples/artists/#alphonse-mucha","text":"Alfons Maria Mucha, known internationally as Alphonse Mucha, was a Czech painter, illustrator and graphic artist, living in Paris during the Art Nouveau period, best known for his distinctly stylized and decorative theatrical posters, particularly those of Sarah Bernhardt. Wikipedia Mucha on Lexica","title":"Alphonse Mucha"},{"location":"examples/artists/#charles-mackintosh","text":"Charles Mackintosh was a Scottish architect, designer, water colorist and artist. His artistic approach had much in common with European Symbolism. His work, alongside that of his wife Margaret Macdonald, was influential on European design movements such as Art Nouveau and Secessionism. He is among the most important figures of Modern Style (British Art Nouveau style). Wikipedia Lexica","title":"Charles Mackintosh"},{"location":"examples/challenges/","text":"","title":"Index"},{"location":"examples/girl-with-laptop/","text":"Girl With Laptop \u00b6 These images are inspired by our Code Savvy mission to represent girls using computers in a positive way. Daybreak \u00b6 A girl lying down with a laptop near a pool in front of pillars with trees, a lake and mountains drawn in the style of Daybreak by Maxfield Parrish. Cave Art \u00b6 Blueprint \u00b6 Stained Glass \u00b6 Photorealistic \u00b6 A 3D render of a young girl with short curly black hair and dark skin having fun programming at a keyboard on her computer with a white background. Graphic Novel \u00b6 Patrick Nagle \u00b6 Gustav Klimpt \u00b6 Magritte \u00b6 Peter Paul Rubens \u00b6 Diego Vlzquez \u00b6","title":"Girl With Laptop"},{"location":"examples/girl-with-laptop/#girl-with-laptop","text":"These images are inspired by our Code Savvy mission to represent girls using computers in a positive way.","title":"Girl With Laptop"},{"location":"examples/girl-with-laptop/#daybreak","text":"A girl lying down with a laptop near a pool in front of pillars with trees, a lake and mountains drawn in the style of Daybreak by Maxfield Parrish.","title":"Daybreak"},{"location":"examples/girl-with-laptop/#cave-art","text":"","title":"Cave Art"},{"location":"examples/girl-with-laptop/#blueprint","text":"","title":"Blueprint"},{"location":"examples/girl-with-laptop/#stained-glass","text":"","title":"Stained Glass"},{"location":"examples/girl-with-laptop/#photorealistic","text":"A 3D render of a young girl with short curly black hair and dark skin having fun programming at a keyboard on her computer with a white background.","title":"Photorealistic"},{"location":"examples/girl-with-laptop/#graphic-novel","text":"","title":"Graphic Novel"},{"location":"examples/girl-with-laptop/#patrick-nagle","text":"","title":"Patrick Nagle"},{"location":"examples/girl-with-laptop/#gustav-klimpt","text":"","title":"Gustav Klimpt"},{"location":"examples/girl-with-laptop/#magritte","text":"","title":"Magritte"},{"location":"examples/girl-with-laptop/#peter-paul-rubens","text":"","title":"Peter Paul Rubens"},{"location":"examples/girl-with-laptop/#diego-vlzquez","text":"","title":"Diego Vlzquez"},{"location":"examples/landscapes/","text":"Landscapes \u00b6 MidJourney Examples \u00b6 [Scene] landscape, painting by Ivan Shishkin, photorealistic, highly detailed, hd, hdr, uhd, unreal engine 5, 8k --ar 3:2 --testp Cottages \u00b6 Stable Diffusion: A cottage with colorful lupine near a stream in the style of Thomas Kinkade.","title":"Landscapes"},{"location":"examples/landscapes/#landscapes","text":"","title":"Landscapes"},{"location":"examples/landscapes/#midjourney-examples","text":"[Scene] landscape, painting by Ivan Shishkin, photorealistic, highly detailed, hd, hdr, uhd, unreal engine 5, 8k --ar 3:2 --testp","title":"MidJourney Examples"},{"location":"examples/landscapes/#cottages","text":"Stable Diffusion: A cottage with colorful lupine near a stream in the style of Thomas Kinkade.","title":"Cottages"},{"location":"examples/landscapes/trees/","text":"Tree Filled Landscapes \u00b6 Prompt \u00b6 A landscape with a red maple tree, a green pine tree, a yellow birch tree, an orange maple tree, with a blue sky and large white puffy clouds. ![][./tree-landscape.jpeg]","title":"Tree Landscapes"},{"location":"examples/landscapes/trees/#tree-filled-landscapes","text":"","title":"Tree Filled Landscapes"},{"location":"examples/landscapes/trees/#prompt","text":"A landscape with a red maple tree, a green pine tree, a yellow birch tree, an orange maple tree, with a blue sky and large white puffy clouds. ![][./tree-landscape.jpeg]","title":"Prompt"},{"location":"products/","text":"Generative Art Products \u00b6 Dall-E 2 \u00b6 Dall-E 2 from OpenAI is the product that has made generative art a key milestone in technology. It is based on the 175B paramerter GPT-3 model. OpenAI DALL-E 2 MidJourney (MJ) \u00b6 MidJourney is a mature commercial text-to-image system that has many command-line options for changing the size of the images generated. MidJourney.com MidJourny uses a Discord system where the user types /imagnine to a bot followed by a prompt. Stable Diffusion \u00b6 Stable Diffusion is a state-of-the-art text-to-image model that generates images from text. HuggingFace Stable Diffusion Typical wait times are over five minutes. Stable Diffusion is the brainchild of Emad Mostaque, a London-based former hedge fund manager whose aim is to bring novel applications of deep learning to the masses through his company, Stability AI. Craiyon \u00b6 An ad-supported text-to-image generation tool with rendering times around one minute. Craiyon.com Craiyon does well on abstract art, but does not render faces well.","title":"Products"},{"location":"products/#generative-art-products","text":"","title":"Generative Art Products"},{"location":"products/#dall-e-2","text":"Dall-E 2 from OpenAI is the product that has made generative art a key milestone in technology. It is based on the 175B paramerter GPT-3 model. OpenAI DALL-E 2","title":"Dall-E 2"},{"location":"products/#midjourney-mj","text":"MidJourney is a mature commercial text-to-image system that has many command-line options for changing the size of the images generated. MidJourney.com MidJourny uses a Discord system where the user types /imagnine to a bot followed by a prompt.","title":"MidJourney (MJ)"},{"location":"products/#stable-diffusion","text":"Stable Diffusion is a state-of-the-art text-to-image model that generates images from text. HuggingFace Stable Diffusion Typical wait times are over five minutes. Stable Diffusion is the brainchild of Emad Mostaque, a London-based former hedge fund manager whose aim is to bring novel applications of deep learning to the masses through his company, Stability AI.","title":"Stable Diffusion"},{"location":"products/#craiyon","text":"An ad-supported text-to-image generation tool with rendering times around one minute. Craiyon.com Craiyon does well on abstract art, but does not render faces well.","title":"Craiyon"},{"location":"products/stable-diffusion/","text":"Stable Diffusion \u00b6 Stable diffusion is a small text-to-image model that runs on consumer-grade GPUs. Background \u00b6 Stable Diffusion was created by Emad Mostaque of stability.ai . Emad was a former hedge fund manager that funded the initial development of stable diffusion. The initial model was trained on a 1,000 node A-100 cluster. The MSRP for each A-100 is $32,097.00 making the cluster value be around $32M. 2.225,000 steps at resolution 512x512 on \"laion-aesthetics v2 5+\" Training Set \u00b6 Hugging Face Dataset Card References \u00b6 Hugging Face Model Card for Stable Diffusion Video \u00b6","title":"Stable Diffusion"},{"location":"products/stable-diffusion/#stable-diffusion","text":"Stable diffusion is a small text-to-image model that runs on consumer-grade GPUs.","title":"Stable Diffusion"},{"location":"products/stable-diffusion/#background","text":"Stable Diffusion was created by Emad Mostaque of stability.ai . Emad was a former hedge fund manager that funded the initial development of stable diffusion. The initial model was trained on a 1,000 node A-100 cluster. The MSRP for each A-100 is $32,097.00 making the cluster value be around $32M. 2.225,000 steps at resolution 512x512 on \"laion-aesthetics v2 5+\"","title":"Background"},{"location":"products/stable-diffusion/#training-set","text":"Hugging Face Dataset Card","title":"Training Set"},{"location":"products/stable-diffusion/#references","text":"Hugging Face Model Card for Stable Diffusion","title":"References"},{"location":"products/stable-diffusion/#video","text":"","title":"Video"}]}