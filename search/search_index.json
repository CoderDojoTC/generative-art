{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Generative Art \u00b6 This site describes the field of generative art: the process of converting narrative text into images. Sample Content What is generative art? Examples of generative art Products that create images from descriptive text Prompt design Concepts Bias Activities Glossary References Contacts","title":"Home"},{"location":"#generative-art","text":"This site describes the field of generative art: the process of converting narrative text into images. Sample Content What is generative art? Examples of generative art Products that create images from descriptive text Prompt design Concepts Bias Activities Glossary References Contacts","title":"Generative Art"},{"location":"01-intro/","text":"Generative Art \u00b6 This site describes the field of generative art: the process of converting narrative text into images. Sample Content What is generative art? Examples of generative art Products that create images from descriptive text Prompt design Concepts Bias Activities Glossary Contacts Source: Types of Cyber Security Roles: Job Growth and Career Paths","title":"Introduction"},{"location":"01-intro/#generative-art","text":"This site describes the field of generative art: the process of converting narrative text into images. Sample Content What is generative art? Examples of generative art Products that create images from descriptive text Prompt design Concepts Bias Activities Glossary Contacts Source: Types of Cyber Security Roles: Job Growth and Career Paths","title":"Generative Art"},{"location":"02-products/","text":"Generative Art Products \u00b6 Dall-E 2 \u00b6 Dall-E 2 from OpenAI is the product that has made generative art a key milestone in technology. It is based on the 175B paramerter GPT-3 model. OpenAI DALL-E 2 MidJourney (MJ) \u00b6 MidJourney is a mature commercial text-to-image system that has many command-line options for changing the size of the images generated. MidJourney.com MidJourny uses a Discord system where the user types /imagnine to a bot followed by a prompt. Stable Diffusion \u00b6 Stable Diffusion is a state-of-the-art text-to-image model that generates images from text. HuggingFace Stable Diffusion Typical wait times are over five minutes. Stable Diffusion is the brainchild of Emad Mostaque, a London-based former hedge fund manager whose aim is to bring novel applications of deep learning to the masses through his company, Stability AI. Craiyon \u00b6 An ad-supported text-to-image generation tool with rendering times around one minute. Craiyon.com Craiyon does well on abstract art, but does not render faces well.","title":"Products"},{"location":"02-products/#generative-art-products","text":"","title":"Generative Art Products"},{"location":"02-products/#dall-e-2","text":"Dall-E 2 from OpenAI is the product that has made generative art a key milestone in technology. It is based on the 175B paramerter GPT-3 model. OpenAI DALL-E 2","title":"Dall-E 2"},{"location":"02-products/#midjourney-mj","text":"MidJourney is a mature commercial text-to-image system that has many command-line options for changing the size of the images generated. MidJourney.com MidJourny uses a Discord system where the user types /imagnine to a bot followed by a prompt.","title":"MidJourney (MJ)"},{"location":"02-products/#stable-diffusion","text":"Stable Diffusion is a state-of-the-art text-to-image model that generates images from text. HuggingFace Stable Diffusion Typical wait times are over five minutes. Stable Diffusion is the brainchild of Emad Mostaque, a London-based former hedge fund manager whose aim is to bring novel applications of deep learning to the masses through his company, Stability AI.","title":"Stable Diffusion"},{"location":"02-products/#craiyon","text":"An ad-supported text-to-image generation tool with rendering times around one minute. Craiyon.com Craiyon does well on abstract art, but does not render faces well.","title":"Craiyon"},{"location":"03-concepts/","text":"Generative Art Concepts \u00b6 Prompt Engineering \u00b6 Zero-Shot Learning \u00b6 Styles \u00b6 Style Transfer \u00b6 Challenges \u00b6 Faces \u00b6 Hands \u00b6","title":"Concepts"},{"location":"03-concepts/#generative-art-concepts","text":"","title":"Generative Art Concepts"},{"location":"03-concepts/#prompt-engineering","text":"","title":"Prompt Engineering"},{"location":"03-concepts/#zero-shot-learning","text":"","title":"Zero-Shot Learning"},{"location":"03-concepts/#styles","text":"","title":"Styles"},{"location":"03-concepts/#style-transfer","text":"","title":"Style Transfer"},{"location":"03-concepts/#challenges","text":"","title":"Challenges"},{"location":"03-concepts/#faces","text":"","title":"Faces"},{"location":"03-concepts/#hands","text":"","title":"Hands"},{"location":"04-prompts/","text":"Prompt Engineering \u00b6","title":"Promt Design"},{"location":"04-prompts/#prompt-engineering","text":"","title":"Prompt Engineering"},{"location":"05-bias/","text":"Bias in Generative Art \u00b6 If you take the prompt, \"A picture of a CIO\", we might get mostly males. This is because many photos that are tagged as \"CEO\" include photos of males. To minimize this bias, generative art programs can detect when occupations are added to the prompt. They can then place gender adjectives before the occupation such as \"male\" or \"female\". Many new generative products do not warn you or correct this problem. Reducing Bias and Improving Safety in DALL\u00b7E 2","title":"Bias"},{"location":"05-bias/#bias-in-generative-art","text":"If you take the prompt, \"A picture of a CIO\", we might get mostly males. This is because many photos that are tagged as \"CEO\" include photos of males. To minimize this bias, generative art programs can detect when occupations are added to the prompt. They can then place gender adjectives before the occupation such as \"male\" or \"female\". Many new generative products do not warn you or correct this problem. Reducing Bias and Improving Safety in DALL\u00b7E 2","title":"Bias in Generative Art"},{"location":"06-fine-tuning/","text":"Fine Tuning a Text-to-Image Model \u00b6 Intro \u00b6 Fine-tuning is the process of adding new layers to an existing model to get it to perform better on a give task. Steps \u00b6 Find an existing model HuggingFace Text-to-Image Models Download the model to your local computer Create a set of images you want to use to fine-tune the model Add new layers to the network and train their weights using these images Waifu Diffusion \u00b6 Waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning. The image dataset for fine tuning was 56k images chosesen from the Danbooru image database. Waifu-diffusion Sample Code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import gradio as gr import torch from torch import autocast from diffusers import StableDiffusionPipeline # our new model ID model_id = \"hakurei/waifu-diffusion\" # use this only if you have a GPU from NVIDIA device = \"cuda\" # we create a new pipeline with our model id using a 16-bit floating point representation pipe = StableDiffusionPipeline . from_pretrained ( model_id , torch_dtype = torch . float16 , revision = 'fp16' ) pipe = pipe . to ( device ) block = gr . Blocks ( css = \".container { max-width: 800px; margin: auto; }\" ) num_samples = 2 def infer ( prompt ): with autocast ( \"cuda\" ): images = pipe ([ prompt ] * num_samples , guidance_scale = 7.5 )[ \"sample\" ] return images with block as demo : gr . Markdown ( \"<h1><center>Waifu Diffusion</center></h1>\" ) gr . Markdown ( \"waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning.\" ) with gr . Group (): with gr . Box (): with gr . Row () . style ( mobile_collapse = False , equal_height = True ): text = gr . Textbox ( label = \"Enter your prompt\" , show_label = False , max_lines = 1 ) . style ( border = ( True , False , True , True ), rounded = ( True , False , False , True ), container = False , ) btn = gr . Button ( \"Run\" ) . style ( margin = False , rounded = ( False , True , True , False ), ) gallery = gr . Gallery ( label = \"Generated images\" , show_label = False ) . style ( grid = [ 2 ], height = \"auto\" ) text . submit ( infer , inputs = [ text ], outputs = gallery ) btn . click ( infer , inputs = [ text ], outputs = gallery ) gr . Markdown ( \"\"\"___ <p style='text-align: center'> Created by https://huggingface.co/hakurei <br/> </p>\"\"\" ) demo . launch ( debug = True )","title":"Fine Tuning"},{"location":"06-fine-tuning/#fine-tuning-a-text-to-image-model","text":"","title":"Fine Tuning a Text-to-Image Model"},{"location":"06-fine-tuning/#intro","text":"Fine-tuning is the process of adding new layers to an existing model to get it to perform better on a give task.","title":"Intro"},{"location":"06-fine-tuning/#steps","text":"Find an existing model HuggingFace Text-to-Image Models Download the model to your local computer Create a set of images you want to use to fine-tune the model Add new layers to the network and train their weights using these images","title":"Steps"},{"location":"06-fine-tuning/#waifu-diffusion","text":"Waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning. The image dataset for fine tuning was 56k images chosesen from the Danbooru image database. Waifu-diffusion","title":"Waifu Diffusion"},{"location":"06-fine-tuning/#sample-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import gradio as gr import torch from torch import autocast from diffusers import StableDiffusionPipeline # our new model ID model_id = \"hakurei/waifu-diffusion\" # use this only if you have a GPU from NVIDIA device = \"cuda\" # we create a new pipeline with our model id using a 16-bit floating point representation pipe = StableDiffusionPipeline . from_pretrained ( model_id , torch_dtype = torch . float16 , revision = 'fp16' ) pipe = pipe . to ( device ) block = gr . Blocks ( css = \".container { max-width: 800px; margin: auto; }\" ) num_samples = 2 def infer ( prompt ): with autocast ( \"cuda\" ): images = pipe ([ prompt ] * num_samples , guidance_scale = 7.5 )[ \"sample\" ] return images with block as demo : gr . Markdown ( \"<h1><center>Waifu Diffusion</center></h1>\" ) gr . Markdown ( \"waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning.\" ) with gr . Group (): with gr . Box (): with gr . Row () . style ( mobile_collapse = False , equal_height = True ): text = gr . Textbox ( label = \"Enter your prompt\" , show_label = False , max_lines = 1 ) . style ( border = ( True , False , True , True ), rounded = ( True , False , False , True ), container = False , ) btn = gr . Button ( \"Run\" ) . style ( margin = False , rounded = ( False , True , True , False ), ) gallery = gr . Gallery ( label = \"Generated images\" , show_label = False ) . style ( grid = [ 2 ], height = \"auto\" ) text . submit ( infer , inputs = [ text ], outputs = gallery ) btn . click ( infer , inputs = [ text ], outputs = gallery ) gr . Markdown ( \"\"\"___ <p style='text-align: center'> Created by https://huggingface.co/hakurei <br/> </p>\"\"\" ) demo . launch ( debug = True )","title":"Sample Code"},{"location":"08-whats-next/","text":"What's Next for Generative Art \u00b6 Image resolution \u00b6 Quality \u00b6 Customizability \u00b6 Video \u00b6","title":"Whats Next"},{"location":"08-whats-next/#whats-next-for-generative-art","text":"","title":"What's Next for Generative Art"},{"location":"08-whats-next/#image-resolution","text":"","title":"Image resolution"},{"location":"08-whats-next/#quality","text":"","title":"Quality"},{"location":"08-whats-next/#customizability","text":"","title":"Customizability"},{"location":"08-whats-next/#video","text":"","title":"Video"},{"location":"contacts/","text":"Generative Art Contacts \u00b6 General Code Savvy Contact \u00b6 kidscode@codesavvy.org Contact for CoderDojo Twin Cities \u00b6 hello@coderdojotc.org Specific questions on this repository \u00b6 Dan McCreary","title":"Contacts"},{"location":"contacts/#generative-art-contacts","text":"","title":"Generative Art Contacts"},{"location":"contacts/#general-code-savvy-contact","text":"kidscode@codesavvy.org","title":"General Code Savvy Contact"},{"location":"contacts/#contact-for-coderdojo-twin-cities","text":"hello@coderdojotc.org","title":"Contact for CoderDojo Twin Cities"},{"location":"contacts/#specific-questions-on-this-repository","text":"Dan McCreary","title":"Specific questions on this repository"},{"location":"glossary/","text":"Glossary of Terms for Text to Image Project \u00b6 API Key \u00b6 A key that is assigned to a developer to use a specific programming interface. The key is used to associate billing with the service. Many commercial text-to-image systems require the user to register with a credit card to get an API Key. Images generated are billed to a credit card each month. Content \u00b6 The information is conveyed by an image. For example, the mood, the message, or the story. Domain \u00b6 The subject matter or context of an image. For example, a landscape, a portrait, a still life, or an abstract image. Embedding \u00b6 A vector of scalar numbers used to map a word or phrase into the mathematical structure for comparison using distance measurements. Fine Tuning \u00b6 The process of adding a small additional output layer to an existing model to give specific results. For example, diagrams that need to conform to Optum 2022 color themes would need to fine-tune a basic model. Gender Bias \u00b6 The tendency of machine learning models to favor one gender or another for specific occupations or roles. For example, the BERT large langugae model generates an 83% chance that a \"nurse\" will be female, but Generative Adversarial Network \u00b6 A neural network architecture used for image generation that uses dueling neural networks to genrate and judge the quality of images. Also known as: GAN Perceptual loss \u00b6 A loss function used in image generation that measures the difference between two images in a way that is perceptually meaningful to humans. Generative Model \u00b6 A machine learning model used to generate images from text descriptions. HuggingFace \u00b6 The largest collection of machine learning models and tools to fine-tune these models. As of August 2022, HuggingFace has 28 image to text models. See HuggingFace Text to Image Models Image synthesis \u00b6 The process of creating a new image from a set of input images. Multi-model Models \u00b6 Models that convert one medium into another medium. For example text-to-image, image-to-text, speech-to-text, text-to-speech etc. Many of the models can be fine-tuned to generate other representations such as text-to-line-art or text-to-architecture-diagram. Texture synthesis \u00b6 The process of creating a texture from a set of input textures Neural Network \u00b6 A machine learning model composed of a large number of interconnected processing nodes, or neurons, that can learn to recognize patterns of input data. Text-to-image models almost all use deep neural networks that contain millions or billions of parameters. Max Tokens \u00b6 The maximum number of tokens used by a prompt. After this limit is reached the text is ignored. The max-tokens for standard language models such as BERT are usually 512 tokens. Larger models such as GPT-3 are 2K or 4K tokens. Style \u00b6 The style used to render an image. For example, a photo, a cartoon, a wireframe, a sketch, line art, a painter or a painting. Prompts that desire a specific style can add the suffix such as \"in the style of...\" Style Transfer \u00b6 The process of creating an image in the style of another style, artist, image or type of image. For example, \"A cat in a field in the style of Vincent Van Goh\" Stable Diffusion \u00b6 The most popular text-to-image model on HuggingFace. See HuggingFace Training Bias \u00b6 The training data used to train a machine learning model. This data can influence the results of the model. Prompt \u00b6 The descriptive text that is given to generate an image. Text to Image \u00b6 The process of generating images from a text description using large langauge models. Tokenization \u00b6 The way that descriptive text is converted into a sequence of numeric values. Small common words are usually a single token. Uncommon multi-syllable words are often many tokens.","title":"Glossary"},{"location":"glossary/#glossary-of-terms-for-text-to-image-project","text":"","title":"Glossary of Terms for Text to Image Project"},{"location":"glossary/#api-key","text":"A key that is assigned to a developer to use a specific programming interface. The key is used to associate billing with the service. Many commercial text-to-image systems require the user to register with a credit card to get an API Key. Images generated are billed to a credit card each month.","title":"API Key"},{"location":"glossary/#content","text":"The information is conveyed by an image. For example, the mood, the message, or the story.","title":"Content"},{"location":"glossary/#domain","text":"The subject matter or context of an image. For example, a landscape, a portrait, a still life, or an abstract image.","title":"Domain"},{"location":"glossary/#embedding","text":"A vector of scalar numbers used to map a word or phrase into the mathematical structure for comparison using distance measurements.","title":"Embedding"},{"location":"glossary/#fine-tuning","text":"The process of adding a small additional output layer to an existing model to give specific results. For example, diagrams that need to conform to Optum 2022 color themes would need to fine-tune a basic model.","title":"Fine Tuning"},{"location":"glossary/#gender-bias","text":"The tendency of machine learning models to favor one gender or another for specific occupations or roles. For example, the BERT large langugae model generates an 83% chance that a \"nurse\" will be female, but","title":"Gender Bias"},{"location":"glossary/#generative-adversarial-network","text":"A neural network architecture used for image generation that uses dueling neural networks to genrate and judge the quality of images. Also known as: GAN","title":"Generative Adversarial Network"},{"location":"glossary/#perceptual-loss","text":"A loss function used in image generation that measures the difference between two images in a way that is perceptually meaningful to humans.","title":"Perceptual loss"},{"location":"glossary/#generative-model","text":"A machine learning model used to generate images from text descriptions.","title":"Generative Model"},{"location":"glossary/#huggingface","text":"The largest collection of machine learning models and tools to fine-tune these models. As of August 2022, HuggingFace has 28 image to text models. See HuggingFace Text to Image Models","title":"HuggingFace"},{"location":"glossary/#image-synthesis","text":"The process of creating a new image from a set of input images.","title":"Image synthesis"},{"location":"glossary/#multi-model-models","text":"Models that convert one medium into another medium. For example text-to-image, image-to-text, speech-to-text, text-to-speech etc. Many of the models can be fine-tuned to generate other representations such as text-to-line-art or text-to-architecture-diagram.","title":"Multi-model Models"},{"location":"glossary/#texture-synthesis","text":"The process of creating a texture from a set of input textures","title":"Texture synthesis"},{"location":"glossary/#neural-network","text":"A machine learning model composed of a large number of interconnected processing nodes, or neurons, that can learn to recognize patterns of input data. Text-to-image models almost all use deep neural networks that contain millions or billions of parameters.","title":"Neural Network"},{"location":"glossary/#max-tokens","text":"The maximum number of tokens used by a prompt. After this limit is reached the text is ignored. The max-tokens for standard language models such as BERT are usually 512 tokens. Larger models such as GPT-3 are 2K or 4K tokens.","title":"Max Tokens"},{"location":"glossary/#style","text":"The style used to render an image. For example, a photo, a cartoon, a wireframe, a sketch, line art, a painter or a painting. Prompts that desire a specific style can add the suffix such as \"in the style of...\"","title":"Style"},{"location":"glossary/#style-transfer","text":"The process of creating an image in the style of another style, artist, image or type of image. For example, \"A cat in a field in the style of Vincent Van Goh\"","title":"Style Transfer"},{"location":"glossary/#stable-diffusion","text":"The most popular text-to-image model on HuggingFace. See HuggingFace","title":"Stable Diffusion"},{"location":"glossary/#training-bias","text":"The training data used to train a machine learning model. This data can influence the results of the model.","title":"Training Bias"},{"location":"glossary/#prompt","text":"The descriptive text that is given to generate an image.","title":"Prompt"},{"location":"glossary/#text-to-image","text":"The process of generating images from a text description using large langauge models.","title":"Text to Image"},{"location":"glossary/#tokenization","text":"The way that descriptive text is converted into a sequence of numeric values. Small common words are usually a single token. Uncommon multi-syllable words are often many tokens.","title":"Tokenization"},{"location":"references/","text":"Generative Art Resources \u00b6 Wikipedia Page on Generative Art Open AI Dall-E 2 Hierarchical Text-Conditional Image Generation with CLIP Latents Ars Technica: With Stable Diffusion, you may never believe what you see online again Sept 6th, 2022 https://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf - This 2015 paper broke ground in the use of GANs to generate human faces.","title":"References"},{"location":"references/#generative-art-resources","text":"Wikipedia Page on Generative Art Open AI Dall-E 2 Hierarchical Text-Conditional Image Generation with CLIP Latents Ars Technica: With Stable Diffusion, you may never believe what you see online again Sept 6th, 2022 https://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf - This 2015 paper broke ground in the use of GANs to generate human faces.","title":"Generative Art Resources"},{"location":"activities/01-intro/","text":"Introduction to Hands-On Activities \u00b6","title":"Introduction"},{"location":"activities/01-intro/#introduction-to-hands-on-activities","text":"","title":"Introduction to Hands-On Activities"},{"location":"activities/02-dalle2/","text":"Dall-E 2 \u00b6","title":"Dall-E 2"},{"location":"activities/02-dalle2/#dall-e-2","text":"","title":"Dall-E 2"},{"location":"activities/03-midjourney/","text":"Network Scavenger Hunt \u00b6 The goal of this activity is to learn to find out how your computer is connected to the internet. Beginning Labs \u00b6 Beginning labs only require a web browser. Lab 1: What is my IP address? \u00b6 Each computer on the internet is assigned its own Internet Protocol Address. What is the address assigned to your computer? (Hint: use a search to find a service that tells you what your IP address is). Lab 2: What is your WiFi network name? \u00b6 Each computer that uses WiFi must connect to the network through a WiFi router that has a name? How can you find out what your WiFi network name is? (Hint: use a search service to find the instructions for your device: Chrome, Windows, Mac, iPad) Lab 3: Who provides your internet connection? \u00b6 Every IP address is managed by a company that connects this address to the internet. That company is called your Internet Services Provider . Here is a tool that will help you find your ISP: https://www.whoismyisp.org/ Lab 4: How fast is your internet connection? \u00b6 Look for a program that can test your connection speed. What is your download and upload speed? What other information can you find about the time it takes to send a short packet of information back and forth from the server (latency). Lab 5: What is your MAC address? \u00b6 For each network interface in your computer, there is a unique MAC address associated with it. This is called the Media Access Control (MAC) address. This number is permanently burned into each device when it is manufactured and it is guaranteed to be unique across the internet. You usually can find MAC addresses in the system settings, general information, or network settings/status of your device. Sometimes the MAC address is printed on a property tag or label so that your organization can track the device. Here are some instructions on finding the MAC address on your Windows or Mac: What's a MAC Address and how do I find it? Note that in this case \"MAC\" has nothing to do with the Apple Mac operating system! Advanced Labs \u00b6 To do these labs, you will need to access your computer's command shell or Terminal (on the Mac). If you are running ChromeOS your school may not have the ChromOS shell installed. Ping Test Lab \u00b6 Ping is a useful program that will help you see the time it takes your computer to communicate with a report computer. It is named after the way that submarines sent out sounds underwater to see what items were near it (sonar). You can use it to debug network problems. Search for how to use the \"ping\" program on your operating systems: How do I run ping on Windows 10\" How do I run ping on a Mac\" How to run a ping test in Chrome OS (requires ChromOS Shell crosh) Video - your school may not have crosh enabled. For example on the Mac use the Terminal and type \"ping -c 10 google.com\". This will measure the time to get from your computer to google.com with a \"count\" of 10. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ ping -c 10 google.com PING google.com ( 142 .250.191.142 ) : 56 data bytes 64 bytes from 142 .250.191.142: icmp_seq = 0 ttl = 50 time = 47 .229 ms 64 bytes from 142 .250.191.142: icmp_seq = 1 ttl = 50 time = 52 .301 ms 64 bytes from 142 .250.191.142: icmp_seq = 2 ttl = 50 time = 43 .634 ms 64 bytes from 142 .250.191.142: icmp_seq = 3 ttl = 50 time = 51 .289 ms 64 bytes from 142 .250.191.142: icmp_seq = 4 ttl = 50 time = 51 .612 ms 64 bytes from 142 .250.191.142: icmp_seq = 5 ttl = 50 time = 51 .738 ms 64 bytes from 142 .250.191.142: icmp_seq = 6 ttl = 50 time = 48 .213 ms 64 bytes from 142 .250.191.142: icmp_seq = 7 ttl = 50 time = 46 .793 ms 64 bytes from 142 .250.191.142: icmp_seq = 8 ttl = 50 time = 56 .455 ms 64 bytes from 142 .250.191.142: icmp_seq = 9 ttl = 50 time = 52 .937 ms --- google.com ping statistics --- 10 packets transmitted, 10 packets received, 0 .0% packet loss round-trip min/avg/max/stddev = 43 .634/50.220/56.455/3.522 ms The last column in the list is the time it took to make a round trip in milliseconds. At the end of the test it will show you the minimum, average, maximum and standard deviation of the 10 trials. The average of 50.22 is a reasonable number. This is about 1/20th of a second. Questions: Why do you think there are variations in the times? What do you think happens if one of the computers connecting your computers goes down? (crashes) Traceroute \u00b6 You can also see the exact route that your computer takes to send data to and from any report system. This is useful for debugging things when your connection to the internet is down. 1 traceroute www.google.com This will show you the times it takes to reach each of the computers between your computers and the destination computer. Search for \"How to use traceroute on Windows/Mac\" for more details.","title":"Midjourney"},{"location":"activities/03-midjourney/#network-scavenger-hunt","text":"The goal of this activity is to learn to find out how your computer is connected to the internet.","title":"Network Scavenger Hunt"},{"location":"activities/03-midjourney/#beginning-labs","text":"Beginning labs only require a web browser.","title":"Beginning Labs"},{"location":"activities/03-midjourney/#lab-1-what-is-my-ip-address","text":"Each computer on the internet is assigned its own Internet Protocol Address. What is the address assigned to your computer? (Hint: use a search to find a service that tells you what your IP address is).","title":"Lab 1: What is my IP address?"},{"location":"activities/03-midjourney/#lab-2-what-is-your-wifi-network-name","text":"Each computer that uses WiFi must connect to the network through a WiFi router that has a name? How can you find out what your WiFi network name is? (Hint: use a search service to find the instructions for your device: Chrome, Windows, Mac, iPad)","title":"Lab 2: What is your WiFi network name?"},{"location":"activities/03-midjourney/#lab-3-who-provides-your-internet-connection","text":"Every IP address is managed by a company that connects this address to the internet. That company is called your Internet Services Provider . Here is a tool that will help you find your ISP: https://www.whoismyisp.org/","title":"Lab 3: Who provides your internet connection?"},{"location":"activities/03-midjourney/#lab-4-how-fast-is-your-internet-connection","text":"Look for a program that can test your connection speed. What is your download and upload speed? What other information can you find about the time it takes to send a short packet of information back and forth from the server (latency).","title":"Lab 4: How fast is your internet connection?"},{"location":"activities/03-midjourney/#lab-5-what-is-your-mac-address","text":"For each network interface in your computer, there is a unique MAC address associated with it. This is called the Media Access Control (MAC) address. This number is permanently burned into each device when it is manufactured and it is guaranteed to be unique across the internet. You usually can find MAC addresses in the system settings, general information, or network settings/status of your device. Sometimes the MAC address is printed on a property tag or label so that your organization can track the device. Here are some instructions on finding the MAC address on your Windows or Mac: What's a MAC Address and how do I find it? Note that in this case \"MAC\" has nothing to do with the Apple Mac operating system!","title":"Lab 5: What is your MAC address?"},{"location":"activities/03-midjourney/#advanced-labs","text":"To do these labs, you will need to access your computer's command shell or Terminal (on the Mac). If you are running ChromeOS your school may not have the ChromOS shell installed.","title":"Advanced Labs"},{"location":"activities/03-midjourney/#ping-test-lab","text":"Ping is a useful program that will help you see the time it takes your computer to communicate with a report computer. It is named after the way that submarines sent out sounds underwater to see what items were near it (sonar). You can use it to debug network problems. Search for how to use the \"ping\" program on your operating systems: How do I run ping on Windows 10\" How do I run ping on a Mac\" How to run a ping test in Chrome OS (requires ChromOS Shell crosh) Video - your school may not have crosh enabled. For example on the Mac use the Terminal and type \"ping -c 10 google.com\". This will measure the time to get from your computer to google.com with a \"count\" of 10. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ ping -c 10 google.com PING google.com ( 142 .250.191.142 ) : 56 data bytes 64 bytes from 142 .250.191.142: icmp_seq = 0 ttl = 50 time = 47 .229 ms 64 bytes from 142 .250.191.142: icmp_seq = 1 ttl = 50 time = 52 .301 ms 64 bytes from 142 .250.191.142: icmp_seq = 2 ttl = 50 time = 43 .634 ms 64 bytes from 142 .250.191.142: icmp_seq = 3 ttl = 50 time = 51 .289 ms 64 bytes from 142 .250.191.142: icmp_seq = 4 ttl = 50 time = 51 .612 ms 64 bytes from 142 .250.191.142: icmp_seq = 5 ttl = 50 time = 51 .738 ms 64 bytes from 142 .250.191.142: icmp_seq = 6 ttl = 50 time = 48 .213 ms 64 bytes from 142 .250.191.142: icmp_seq = 7 ttl = 50 time = 46 .793 ms 64 bytes from 142 .250.191.142: icmp_seq = 8 ttl = 50 time = 56 .455 ms 64 bytes from 142 .250.191.142: icmp_seq = 9 ttl = 50 time = 52 .937 ms --- google.com ping statistics --- 10 packets transmitted, 10 packets received, 0 .0% packet loss round-trip min/avg/max/stddev = 43 .634/50.220/56.455/3.522 ms The last column in the list is the time it took to make a round trip in milliseconds. At the end of the test it will show you the minimum, average, maximum and standard deviation of the 10 trials. The average of 50.22 is a reasonable number. This is about 1/20th of a second. Questions: Why do you think there are variations in the times? What do you think happens if one of the computers connecting your computers goes down? (crashes)","title":"Ping Test Lab"},{"location":"activities/03-midjourney/#traceroute","text":"You can also see the exact route that your computer takes to send data to and from any report system. This is useful for debugging things when your connection to the internet is down. 1 traceroute www.google.com This will show you the times it takes to reach each of the computers between your computers and the destination computer. Search for \"How to use traceroute on Windows/Mac\" for more details.","title":"Traceroute"},{"location":"activities/04-stable-diffusion/","text":"Stable Diffusion Lab \u00b6 This lab is challenging since the render time on the HuggingFace site is around five minutes, so we will only perform a few tests. Girl at Computer \u00b6 Prompt: An African girl having fun at her computer. Result: This prompt shows that Stable Diffusion does well at faces, but falls short when rendering hands.","title":"Stable Diffusion"},{"location":"activities/04-stable-diffusion/#stable-diffusion-lab","text":"This lab is challenging since the render time on the HuggingFace site is around five minutes, so we will only perform a few tests.","title":"Stable Diffusion Lab"},{"location":"activities/04-stable-diffusion/#girl-at-computer","text":"Prompt: An African girl having fun at her computer. Result: This prompt shows that Stable Diffusion does well at faces, but falls short when rendering hands.","title":"Girl at Computer"},{"location":"activities/05-crayion/","text":"Crayion Lab \u00b6 Go to the web site http://www.craiyon.com and enter a prompt. Example: A happy African girl at her computer","title":"Crayion"},{"location":"activities/05-crayion/#crayion-lab","text":"Go to the web site http://www.craiyon.com and enter a prompt. Example: A happy African girl at her computer","title":"Crayion Lab"}]}